{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b7152e",
   "metadata": {},
   "source": [
    "# NLP Assignment 1: Thatâ€™s What I LIKE (Complete Pipeline)\n",
    "\n",
    "This notebook contains the complete implementation for the NLP Assignment. All outputs and data are stored within the `git` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588be60",
   "metadata": {},
   "source": [
    "## 0. Setup & Configuration\n",
    "Ensure we are running in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4953effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /Users/htutkoko/Library/CloudStorage/OneDrive-AsianInstituteofTechnology/AIT_Study/AT82.05_NLP/A1/git\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. Set Working Directory to 'git' folder\n",
    "if os.path.exists('git') and os.path.isdir('git'):\n",
    "    os.chdir('git')\n",
    "    print(f\"Changed directory to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# 2. Create necessary directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('nltk_data', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036059d",
   "metadata": {},
   "source": [
    "## 1. Data Loader\n",
    "\n",
    "Handles loading the Reuters corpus, building vocabulary, and numericalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362b6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/reuters')\n",
    "except LookupError:\n",
    "    print(\"Downloading reuters corpus...\")\n",
    "    nltk.download('reuters', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n",
    "    nltk.download('punkt_tab', download_dir=nltk_data_dir, quiet=True)\n",
    "\n",
    "import zipfile\n",
    "reuters_zip_path = os.path.join(nltk_data_dir, 'corpora', 'reuters.zip')\n",
    "reuters_dir_path = os.path.join(nltk_data_dir, 'corpora', 'reuters')\n",
    "\n",
    "if os.path.exists(reuters_zip_path) and not os.path.exists(reuters_dir_path):\n",
    "    print(f\"Unzipping {reuters_zip_path}...\")\n",
    "    with zipfile.ZipFile(reuters_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(nltk_data_dir, 'corpora'))\n",
    "    print(\"Unzipping complete.\")\n",
    "\n",
    "MIN_FREQ = 5 # Minimum frequency for words to be included in vocab\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, min_freq=MIN_FREQ):\n",
    "        self.min_freq = min_freq\n",
    "        self.categories = None # Use full corpus\n",
    "        print(f\"Loading Reuters corpus (Full)...\")\n",
    "        \n",
    "        self.sentences = reuters.sents()\n",
    "        self.corpus = [[word.lower() for word in sent] for sent in self.sentences]\n",
    "        \n",
    "        print(f\"Corpus size: {len(self.corpus)} sentences\")\n",
    "        \n",
    "        self.build_vocab()\n",
    "        \n",
    "    def build_vocab(self):\n",
    "        print(\"Building vocabulary...\")\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        self.all_words = flatten(self.corpus)\n",
    "        self.word_count = Counter(self.all_words)\n",
    "        \n",
    "        self.vocab = [w for w, c in self.word_count.items() if c >= self.min_freq]\n",
    "        self.vocab.append('<UNK>')\n",
    "        \n",
    "        self.word2index = {w: i for i, w in enumerate(self.vocab)}\n",
    "        self.index2word = {i: w for w, i in self.word2index.items()}\n",
    "        self.voc_size = len(self.vocab)\n",
    "        \n",
    "        print(f\"Vocabulary size: {self.voc_size}\")\n",
    "        \n",
    "    def get_numericalized_corpus(self):\n",
    "        unk_idx = self.word2index['<UNK>']\n",
    "        numericalized_corpus = []\n",
    "        for sent in self.corpus:\n",
    "            sent_indices = [self.word2index.get(w, unk_idx) for w in sent]\n",
    "            numericalized_corpus.append(sent_indices)\n",
    "        return numericalized_corpus\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "        \n",
    "    def get_word2index(self):\n",
    "        return self.word2index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ead15e",
   "metadata": {},
   "source": [
    "## 2. Model Definitions\n",
    "\n",
    "PyTorch classes for Skipgram, Negative Sampling, and GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1961db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center) \n",
    "        outside_embedding    = self.embedding_outside(outside) \n",
    "        all_vocabs_embedding = self.embedding_outside(all_vocabs) \n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) \n",
    "        \n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum)) \n",
    "        return loss\n",
    "\n",
    "class SkipgramNeg(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid        = nn.LogSigmoid()\n",
    "    \n",
    "    def forward(self, center, outside, negative):\n",
    "        center_embed   = self.embedding_center(center) \n",
    "        outside_embed  = self.embedding_outside(outside) \n",
    "        negative_embed = self.embedding_outside(negative) \n",
    "        \n",
    "        uovc = outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) \n",
    "        ukvc = -negative_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) \n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + torch.sum(self.logsigmoid(ukvc), 1).unsqueeze(1)\n",
    "        return -torch.mean(loss)\n",
    "\n",
    "class Glove(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Glove, self).__init__()\n",
    "        self.center_embedding  = nn.Embedding(voc_size, emb_size)\n",
    "        self.outside_embedding = nn.Embedding(voc_size, emb_size)\n",
    "        self.center_bias       = nn.Embedding(voc_size, 1) \n",
    "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
    "    \n",
    "    def forward(self, center, outside, coocs, weighting):\n",
    "        center_embeds  = self.center_embedding(center) \n",
    "        outside_embeds = self.outside_embedding(outside) \n",
    "        \n",
    "        center_bias    = self.center_bias(center).squeeze(1)\n",
    "        target_bias    = self.outside_bias(outside).squeeze(1)\n",
    "        \n",
    "        inner_product  = outside_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        \n",
    "        loss = weighting * torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
    "        return torch.sum(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3b91b",
   "metadata": {},
   "source": [
    "## 3. Training Word2Vec (Skipgram)\n",
    "\n",
    "**Note**: Training on full Reuters corpus might take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e7a1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters corpus (Full)...\n",
      "Corpus size: 54716 sentences\n",
      "Building vocabulary...\n",
      "Vocabulary size: 11678\n",
      "Vocab Size: 11678\n",
      "Training Skipgram (Window Size=2, Emb Size=10, Epochs=5)...\n",
      "Total Tokens: 1720917\n",
      "Steps per epoch: 13444\n",
      "  Step 1000/13444 | Loss: 10.726004\n",
      "  Step 2000/13444 | Loss: 9.221310\n",
      "  Step 3000/13444 | Loss: 7.893904\n",
      "  Step 4000/13444 | Loss: 7.371448\n",
      "  Step 5000/13444 | Loss: 7.016697\n",
      "  Step 6000/13444 | Loss: 6.769714\n",
      "  Step 7000/13444 | Loss: 6.613394\n",
      "  Step 8000/13444 | Loss: 6.561038\n",
      "  Step 9000/13444 | Loss: 6.647599\n",
      "  Step 10000/13444 | Loss: 6.428586\n",
      "  Step 11000/13444 | Loss: 6.461717\n",
      "  Step 12000/13444 | Loss: 6.460613\n",
      "  Step 13000/13444 | Loss: 6.290025\n",
      "Epoch      1 | Avg Loss: 7.491995 | Time: 7270.4656s\n",
      "  Step 1000/13444 | Loss: 6.179290\n",
      "  Step 2000/13444 | Loss: 6.227787\n",
      "  Step 3000/13444 | Loss: 6.393227\n",
      "  Step 4000/13444 | Loss: 6.253748\n",
      "  Step 5000/13444 | Loss: 6.103871\n",
      "  Step 6000/13444 | Loss: 6.436166\n",
      "  Step 7000/13444 | Loss: 6.297138\n",
      "  Step 8000/13444 | Loss: 6.253543\n",
      "  Step 9000/13444 | Loss: 6.228369\n",
      "  Step 10000/13444 | Loss: 6.258429\n",
      "  Step 11000/13444 | Loss: 6.267446\n",
      "  Step 12000/13444 | Loss: 6.185546\n",
      "  Step 13000/13444 | Loss: 6.102095\n",
      "Epoch      2 | Avg Loss: 6.268286 | Time: 4826.9736s\n",
      "  Step 1000/13444 | Loss: 5.903317\n",
      "  Step 2000/13444 | Loss: 6.140361\n",
      "  Step 3000/13444 | Loss: 6.149141\n",
      "  Step 4000/13444 | Loss: 6.201736\n",
      "  Step 5000/13444 | Loss: 6.026156\n",
      "  Step 6000/13444 | Loss: 6.259743\n",
      "  Step 7000/13444 | Loss: 6.189206\n",
      "  Step 8000/13444 | Loss: 5.957506\n",
      "  Step 9000/13444 | Loss: 6.312661\n",
      "  Step 10000/13444 | Loss: 6.136456\n",
      "  Step 11000/13444 | Loss: 5.983143\n",
      "  Step 12000/13444 | Loss: 6.133326\n",
      "  Step 13000/13444 | Loss: 6.240994\n",
      "Epoch      3 | Avg Loss: 6.172522 | Time: 4587.3052s\n",
      "  Step 1000/13444 | Loss: 6.165089\n",
      "  Step 2000/13444 | Loss: 6.081910\n",
      "  Step 3000/13444 | Loss: 6.085954\n",
      "  Step 4000/13444 | Loss: 6.202025\n",
      "  Step 5000/13444 | Loss: 6.021138\n",
      "  Step 6000/13444 | Loss: 5.963983\n",
      "  Step 7000/13444 | Loss: 6.041748\n",
      "  Step 8000/13444 | Loss: 6.133562\n",
      "  Step 9000/13444 | Loss: 5.996552\n",
      "  Step 10000/13444 | Loss: 5.998940\n",
      "  Step 11000/13444 | Loss: 5.969808\n",
      "  Step 12000/13444 | Loss: 6.137800\n",
      "  Step 13000/13444 | Loss: 6.198271\n",
      "Epoch      4 | Avg Loss: 6.136221 | Time: 5779.7441s\n",
      "  Step 1000/13444 | Loss: 5.944956\n",
      "  Step 2000/13444 | Loss: 5.932628\n",
      "  Step 3000/13444 | Loss: 6.033872\n",
      "  Step 4000/13444 | Loss: 6.099108\n",
      "  Step 5000/13444 | Loss: 6.461678\n",
      "  Step 6000/13444 | Loss: 6.266243\n",
      "  Step 7000/13444 | Loss: 6.152428\n",
      "  Step 8000/13444 | Loss: 6.121257\n",
      "  Step 9000/13444 | Loss: 6.125789\n",
      "  Step 10000/13444 | Loss: 6.190082\n",
      "  Step 11000/13444 | Loss: 6.086619\n",
      "  Step 12000/13444 | Loss: 5.949760\n",
      "  Step 13000/13444 | Loss: 6.076856\n",
      "Epoch      5 | Avg Loss: 6.114304 | Time: 11921.0933s\n",
      "Model saved to models/skipgram_model.pth\n",
      "Metrics saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "loader = DataLoader() # min_freq=5\n",
    "corpus = loader.get_numericalized_corpus()\n",
    "voc_size = loader.voc_size\n",
    "word2index = loader.get_word2index()\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "print(f\"Vocab Size: {voc_size}\")\n",
    "\n",
    "def generate_skipgrams(corpus, window_size=2):\n",
    "    skipgrams = []\n",
    "    for doc in corpus:\n",
    "        for i in range(window_size, len(doc)-window_size):\n",
    "            center = doc[i]\n",
    "            outside = []\n",
    "            for w in range(1, window_size+1):\n",
    "                outside.append(doc[i-w])\n",
    "                outside.append(doc[i+w])\n",
    "            \n",
    "            for each_out in outside:\n",
    "                skipgrams.append([center, each_out])\n",
    "    return skipgrams\n",
    "\n",
    "def get_batch(corpus, batch_size, window_size=2):\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    \n",
    "    while len(inputs) < batch_size:\n",
    "        doc_idx = np.random.randint(0, len(corpus))\n",
    "        doc = corpus[doc_idx]\n",
    "        \n",
    "        if len(doc) < 2 * window_size + 1:\n",
    "            continue\n",
    "            \n",
    "        center_idx = np.random.randint(window_size, len(doc) - window_size)\n",
    "        center = doc[center_idx]\n",
    "        \n",
    "        offsets = list(range(-window_size, 0)) + list(range(1, window_size + 1))\n",
    "        offset = np.random.choice(offsets)\n",
    "        outside = doc[center_idx + offset]\n",
    "        \n",
    "        inputs.append([center])\n",
    "        labels.append([outside])\n",
    "        \n",
    "    return np.array(inputs), np.array(labels)\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n",
    "        outside_embedding    = self.embedding_outside(outside) #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embedding = self.embedding_outside(all_vocabs) #(batch_size, voc_size, emb_size) \n",
    "        \n",
    "        all_vocabs_embedding = self.embedding_outside(all_vocabs)\n",
    "        outside_embedding = self.embedding_outside(outside)\n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
    "\n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
    "        \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n",
    "        \n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n",
    "        return loss\n",
    "\n",
    "device = torch.device('cpu') # Use CPU for now as default\n",
    "device = torch.device('cpu') # Use CPU for now as default\n",
    "batch_size = 512 # Increased for faster pure-python batching\n",
    "emb_size   = 2 # Instruction says \"Compare... models\". Usually embedding size is larger but notebook used 2. \n",
    "EMB_SIZE = 10 \n",
    "\n",
    "model      = Skipgram(voc_size, EMB_SIZE).to(device)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "all_vocabs = torch.LongTensor(list(range(voc_size))).unsqueeze(0).expand(batch_size, voc_size).to(device)\n",
    "\n",
    "num_epochs = 5 # Reduced epochs because each epoch is now FULL pass (much longer)\n",
    "print(f\"Training Skipgram (Window Size=2, Emb Size={EMB_SIZE}, Epochs={num_epochs})...\")\n",
    "\n",
    "num_tokens = sum([len(doc) for doc in corpus])\n",
    "print(f\"Total Tokens: {num_tokens}\")\n",
    "fields_per_token = 2 # window size 2 -> 2 pairs left, 2 pairs right? No, dynamic.\n",
    "approx_total_pairs = num_tokens * 2 * 2 \n",
    "steps_per_epoch = max(1, approx_total_pairs // batch_size)\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(num_epochs):    \n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        input_batch, label_batch = get_batch(corpus, batch_size, window_size=2)\n",
    "        input_tensor = torch.LongTensor(input_batch).to(device)\n",
    "        label_tensor = torch.LongTensor(label_batch).to(device)\n",
    "        \n",
    "        loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % 1000 == 0:\n",
    "            print(f\"  Step {step+1}/{steps_per_epoch} | Loss: {loss.item():.6f}\")\n",
    "\n",
    "    end = time.time()\n",
    "    avg_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch+1:6.0f} | Avg Loss: {avg_loss:.6f} | Time: {end-start:.4f}s\")\n",
    "\n",
    "save_path = 'models/skipgram_model.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")\n",
    "\n",
    "import json\n",
    "metrics_path = 'models/metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "else:\n",
    "    metrics = {}\n",
    "\n",
    "metrics['Skipgram'] = {\n",
    "    'window_size': 2,\n",
    "    'training_loss': avg_loss,\n",
    "    'training_time': time.time() - total_start\n",
    "}\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "print(\"Metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f3688",
   "metadata": {},
   "source": [
    "## 4. Training Word2Vec (Negative Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635e4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters corpus (Full)...\n",
      "Corpus size: 54716 sentences\n",
      "Building vocabulary...\n",
      "Vocabulary size: 11678\n",
      "Preparing Unigram Table...\n",
      "Unigram Table Size: 3393\n",
      "Training SkipgramNEG (Window=2, Emb=10, Epochs=5, k=5)...\n",
      "Total Tokens: 1720917\n",
      "Steps per epoch: 13444\n",
      "  Step 1000/13444 | Loss: 5.571229\n",
      "  Step 2000/13444 | Loss: 4.086699\n",
      "  Step 3000/13444 | Loss: 3.293912\n",
      "  Step 4000/13444 | Loss: 2.950686\n",
      "  Step 5000/13444 | Loss: 2.591558\n",
      "  Step 6000/13444 | Loss: 2.452118\n",
      "  Step 7000/13444 | Loss: 2.460414\n",
      "  Step 8000/13444 | Loss: 2.381029\n",
      "  Step 9000/13444 | Loss: 2.298933\n",
      "  Step 10000/13444 | Loss: 2.291488\n",
      "  Step 11000/13444 | Loss: 2.259181\n",
      "  Step 12000/13444 | Loss: 2.243899\n",
      "  Step 13000/13444 | Loss: 2.140116\n",
      "Epoch      1 | Avg Loss: 3.038960 | Time: 322.2942s\n",
      "  Step 1000/13444 | Loss: 2.129869\n",
      "  Step 2000/13444 | Loss: 2.122855\n",
      "  Step 3000/13444 | Loss: 2.151317\n",
      "  Step 4000/13444 | Loss: 2.112882\n",
      "  Step 5000/13444 | Loss: 2.069285\n",
      "  Step 6000/13444 | Loss: 2.053159\n",
      "  Step 7000/13444 | Loss: 2.106566\n",
      "  Step 8000/13444 | Loss: 2.158652\n",
      "  Step 9000/13444 | Loss: 2.104970\n",
      "  Step 10000/13444 | Loss: 2.133128\n",
      "  Step 11000/13444 | Loss: 2.122715\n",
      "  Step 12000/13444 | Loss: 1.956242\n",
      "  Step 13000/13444 | Loss: 2.018073\n",
      "Epoch      2 | Avg Loss: 2.089393 | Time: 208.7832s\n",
      "  Step 1000/13444 | Loss: 1.991873\n",
      "  Step 2000/13444 | Loss: 2.013820\n",
      "  Step 3000/13444 | Loss: 2.069998\n",
      "  Step 4000/13444 | Loss: 2.049156\n",
      "  Step 5000/13444 | Loss: 2.062982\n",
      "  Step 6000/13444 | Loss: 1.976038\n",
      "  Step 7000/13444 | Loss: 2.039093\n",
      "  Step 8000/13444 | Loss: 1.972332\n",
      "  Step 9000/13444 | Loss: 1.991465\n",
      "  Step 10000/13444 | Loss: 1.973613\n",
      "  Step 11000/13444 | Loss: 2.055953\n",
      "  Step 12000/13444 | Loss: 2.010214\n",
      "  Step 13000/13444 | Loss: 1.994346\n",
      "Epoch      3 | Avg Loss: 2.014875 | Time: 220.6929s\n",
      "  Step 1000/13444 | Loss: 1.919488\n",
      "  Step 2000/13444 | Loss: 1.988985\n",
      "  Step 3000/13444 | Loss: 1.931521\n",
      "  Step 4000/13444 | Loss: 2.041149\n",
      "  Step 5000/13444 | Loss: 1.982748\n",
      "  Step 6000/13444 | Loss: 1.940848\n",
      "  Step 7000/13444 | Loss: 2.029166\n",
      "  Step 8000/13444 | Loss: 1.956124\n",
      "  Step 9000/13444 | Loss: 1.983238\n",
      "  Step 10000/13444 | Loss: 1.908427\n",
      "  Step 11000/13444 | Loss: 1.972599\n",
      "  Step 12000/13444 | Loss: 1.939671\n",
      "  Step 13000/13444 | Loss: 1.966315\n",
      "Epoch      4 | Avg Loss: 1.988873 | Time: 274.7918s\n",
      "  Step 1000/13444 | Loss: 1.996270\n",
      "  Step 2000/13444 | Loss: 1.920313\n",
      "  Step 3000/13444 | Loss: 1.937554\n",
      "  Step 4000/13444 | Loss: 1.908419\n",
      "  Step 5000/13444 | Loss: 2.032261\n",
      "  Step 6000/13444 | Loss: 1.961516\n",
      "  Step 7000/13444 | Loss: 1.967303\n",
      "  Step 8000/13444 | Loss: 2.027537\n",
      "  Step 9000/13444 | Loss: 1.895942\n",
      "  Step 10000/13444 | Loss: 2.025429\n",
      "  Step 11000/13444 | Loss: 2.036288\n",
      "  Step 12000/13444 | Loss: 2.044492\n",
      "  Step 13000/13444 | Loss: 1.917245\n",
      "Epoch      5 | Avg Loss: 1.976713 | Time: 200.7638s\n",
      "Model saved to models/skipgram_neg_model.pth\n",
      "Metrics saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "loader = DataLoader()\n",
    "corpus = loader.get_numericalized_corpus()\n",
    "voc_size = loader.voc_size\n",
    "word2index = loader.get_word2index()\n",
    "\n",
    "print(\"Preparing Unigram Table...\")\n",
    "word_count = loader.word_count\n",
    "total_words = sum(word_count.values())\n",
    "unigram_table = []\n",
    "z = 0.001\n",
    "for w in loader.vocab:\n",
    "    if w == '<UNK>': continue\n",
    "    idx = word2index[w]\n",
    "    uw = word_count[w] / total_words\n",
    "    uw_alpha = int((uw ** 0.75) / z)\n",
    "    unigram_table.extend([idx] * uw_alpha)\n",
    "\n",
    "if '<UNK>' in word2index:\n",
    "    unk_idx = word2index['<UNK>']\n",
    "    unigram_table.extend([unk_idx] * 10)\n",
    "\n",
    "print(f\"Unigram Table Size: {len(unigram_table)}\")\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):\n",
    "        target_index = targets[i].item()\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            if neg == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(nsample)\n",
    "    return torch.LongTensor(neg_samples)\n",
    "\n",
    "def get_batch(corpus, batch_size, window_size=2):\n",
    "    inputs, labels = [], []\n",
    "    while len(inputs) < batch_size:\n",
    "        doc_idx = np.random.randint(0, len(corpus))\n",
    "        doc = corpus[doc_idx]\n",
    "        if len(doc) < 2 * window_size + 1:\n",
    "            continue\n",
    "        center_idx = np.random.randint(window_size, len(doc) - window_size)\n",
    "        center = doc[center_idx]\n",
    "        offsets = list(range(-window_size, 0)) + list(range(1, window_size + 1))\n",
    "        offset = np.random.choice(offsets)\n",
    "        outside = doc[center_idx + offset]\n",
    "        inputs.append([center])\n",
    "        labels.append([outside])\n",
    "    return np.array(inputs), np.array(labels)\n",
    "\n",
    "class SkipgramNeg(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid        = nn.LogSigmoid()\n",
    "    \n",
    "    def forward(self, center, outside, negative):\n",
    "        \n",
    "        center_embed   = self.embedding_center(center) #(bs, 1, emb_size)\n",
    "        outside_embed  = self.embedding_outside(outside) #(bs, 1, emb_size)\n",
    "        negative_embed = self.embedding_outside(negative) #(bs, k, emb_size) # Use outside embedding for negative samples\n",
    "        \n",
    "        uovc = outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) #(bs, 1)\n",
    "        \n",
    "        ukvc = -negative_embed.bmm(center_embed.transpose(1, 2)).squeeze(2) #(bs, k)\n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + torch.sum(self.logsigmoid(ukvc), 1).unsqueeze(1)\n",
    "        \n",
    "        return -torch.mean(loss)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "batch_size = 512\n",
    "emb_size   = 10\n",
    "model      = SkipgramNeg(voc_size, emb_size).to(device)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "k = 5 # negative samples\n",
    "\n",
    "print(f\"Training SkipgramNEG (Window=2, Emb={emb_size}, Epochs={num_epochs}, k={k})...\")\n",
    "\n",
    "num_tokens = sum([len(doc) for doc in corpus])\n",
    "print(f\"Total Tokens: {num_tokens}\")\n",
    "approx_total_pairs = num_tokens * 2 * 2 \n",
    "steps_per_epoch = max(1, approx_total_pairs // batch_size)\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        input_batch, label_batch = get_batch(corpus, batch_size, window_size=2)\n",
    "        input_tensor = torch.LongTensor(input_batch).to(device)\n",
    "        label_tensor = torch.LongTensor(label_batch).to(device)\n",
    "        \n",
    "        neg_tensor = negative_sampling(label_tensor, unigram_table, k).to(device)\n",
    "        \n",
    "        loss = model(input_tensor, label_tensor, neg_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % 1000 == 0:\n",
    "             print(f\"  Step {step+1}/{steps_per_epoch} | Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch+1:6.0f} | Avg Loss: {avg_loss:.6f} | Time: {end-start:.4f}s\")\n",
    "\n",
    "save_path = 'models/skipgram_neg_model.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")\n",
    "\n",
    "import json\n",
    "metrics_path = 'models/metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "else:\n",
    "    metrics = {}\n",
    "\n",
    "metrics['SkipgramNeg'] = {\n",
    "    'window_size': 2,\n",
    "    'training_loss': avg_loss,\n",
    "    'training_time': time.time() - total_start\n",
    "}\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "print(\"Metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b9344",
   "metadata": {},
   "source": [
    "## 5. Training GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd97c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters corpus (Full)...\n",
      "Corpus size: 54716 sentences\n",
      "Building vocabulary...\n",
      "Vocabulary size: 11678\n",
      "Building Co-occurrence Matrix...\n",
      "Calculating weights...\n",
      "Number of non-zero co-occurrences: 1133669\n",
      "Training GloVe (Window=2, Emb=10, Epochs=10)...\n",
      "Non-zero pairs: 1133669\n",
      "Steps per epoch: 2214\n",
      "  Step 1000/2214 | Loss: 417.342957\n",
      "  Step 2000/2214 | Loss: 448.408142\n",
      "Epoch      1 | Avg Loss: 532.013049 | Time: 137.6871s\n",
      "  Step 1000/2214 | Loss: 333.404541\n",
      "  Step 2000/2214 | Loss: 226.810791\n",
      "Epoch      2 | Avg Loss: 307.359025 | Time: 134.1092s\n",
      "  Step 1000/2214 | Loss: 247.821884\n",
      "  Step 2000/2214 | Loss: 117.673737\n",
      "Epoch      3 | Avg Loss: 190.457472 | Time: 129.2668s\n",
      "  Step 1000/2214 | Loss: 107.190239\n",
      "  Step 2000/2214 | Loss: 121.762245\n",
      "Epoch      4 | Avg Loss: 126.837518 | Time: 105.4103s\n",
      "  Step 1000/2214 | Loss: 86.170609\n",
      "  Step 2000/2214 | Loss: 59.505257\n",
      "Epoch      5 | Avg Loss: 90.837703 | Time: 104.9334s\n",
      "  Step 1000/2214 | Loss: 67.582878\n",
      "  Step 2000/2214 | Loss: 55.343586\n",
      "Epoch      6 | Avg Loss: 69.961272 | Time: 108.8225s\n",
      "  Step 1000/2214 | Loss: 50.453022\n",
      "  Step 2000/2214 | Loss: 49.753746\n",
      "Epoch      7 | Avg Loss: 56.489474 | Time: 108.2241s\n",
      "  Step 1000/2214 | Loss: 46.029728\n",
      "  Step 2000/2214 | Loss: 66.045349\n",
      "Epoch      8 | Avg Loss: 48.038877 | Time: 106.5014s\n",
      "  Step 1000/2214 | Loss: 35.633453\n",
      "  Step 2000/2214 | Loss: 42.949177\n",
      "Epoch      9 | Avg Loss: 42.761892 | Time: 106.9725s\n",
      "  Step 1000/2214 | Loss: 42.899300\n",
      "  Step 2000/2214 | Loss: 30.905130\n",
      "Epoch     10 | Avg Loss: 38.933884 | Time: 106.0299s\n",
      "Model saved to models/glove_model.pth\n",
      "Metrics saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import combinations_with_replacement\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "loader = DataLoader() # min_freq=5\n",
    "corpus = loader.get_numericalized_corpus()\n",
    "voc_size = loader.voc_size\n",
    "vocab = loader.vocab\n",
    "word2index = loader.get_word2index()\n",
    "\n",
    "print(\"Building Co-occurrence Matrix...\")\n",
    "X_ik = {}\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "skip_grams = []\n",
    "for doc in corpus:\n",
    "    for i in range(1, len(doc)-1):\n",
    "        center = doc[i]\n",
    "        start = max(0, i - WINDOW_SIZE)\n",
    "        end = min(len(doc), i + WINDOW_SIZE + 1)\n",
    "        outside = [doc[j] for j in range(start, end) if j != i]\n",
    "        \n",
    "        for each_out in outside:\n",
    "            skip_grams.append((center, each_out))\n",
    "            \n",
    "X_ik_skipgrams = Counter(skip_grams)\n",
    "\n",
    "weighting_dic = {}\n",
    "X_ik = {}\n",
    "\n",
    "def weighting(x_ij):\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "    if x_ij < x_max:\n",
    "        return (x_ij / x_max)**alpha\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "print(\"Calculating weights...\")\n",
    "for bigram, count in X_ik_skipgrams.items():\n",
    "    X_ik[bigram] = count\n",
    "    weighting_dic[bigram] = weighting(count)\n",
    "\n",
    "skip_grams_keys = list(X_ik.keys())\n",
    "print(f\"Number of non-zero co-occurrences: {len(skip_grams_keys)}\")\n",
    "\n",
    "class Glove(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Glove, self).__init__()\n",
    "        self.center_embedding  = nn.Embedding(voc_size, emb_size)\n",
    "        self.outside_embedding = nn.Embedding(voc_size, emb_size)\n",
    "        self.center_bias       = nn.Embedding(voc_size, 1) \n",
    "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
    "    \n",
    "    def forward(self, center, outside, coocs, weighting):\n",
    "        center_embeds  = self.center_embedding(center) #(batch_size, 1, emb_size)\n",
    "        outside_embeds = self.outside_embedding(outside) #(batch_size, 1, emb_size)\n",
    "        \n",
    "        center_bias    = self.center_bias(center).squeeze(1)\n",
    "        target_bias    = self.outside_bias(outside).squeeze(1)\n",
    "        \n",
    "        inner_product  = outside_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        \n",
    "        loss = weighting * torch.pow(inner_product + center_bias + target_bias - coocs, 2)\n",
    "        return torch.sum(loss)\n",
    "\n",
    "def get_batch(batch_size, skip_grams_keys, X_ik, weighting_dic):\n",
    "    random_inputs, random_labels, random_coocs, random_weightings = [], [], [], []\n",
    "    \n",
    "    indices = np.random.choice(len(skip_grams_keys), batch_size, replace=False)\n",
    "    \n",
    "    for i in indices:\n",
    "        pair = skip_grams_keys[i]\n",
    "        center, outside = pair\n",
    "        random_inputs.append([center])\n",
    "        random_labels.append([outside])\n",
    "        \n",
    "        cooc = X_ik[pair]\n",
    "        random_coocs.append([math.log(cooc)])\n",
    "        random_weightings.append([weighting_dic[pair]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "batch_size = 512\n",
    "emb_size   = 10\n",
    "model      = Glove(voc_size, emb_size).to(device)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10 # GloVe converges faster, but let's do 10 full passes\n",
    "print(f\"Training GloVe (Window=2, Emb={emb_size}, Epochs={num_epochs})...\")\n",
    "print(f\"Non-zero pairs: {len(skip_grams_keys)}\")\n",
    "\n",
    "steps_per_epoch = max(1, len(skip_grams_keys) // batch_size)\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    random.shuffle(skip_grams_keys)\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        \n",
    "        input_batch, target_batch, cooc_batch, weighting_batch = get_batch(batch_size, skip_grams_keys, X_ik, weighting_dic)\n",
    "        \n",
    "        input_batch  = torch.LongTensor(input_batch).to(device)\n",
    "        target_batch = torch.LongTensor(target_batch).to(device)\n",
    "        cooc_batch   = torch.FloatTensor(cooc_batch).to(device)\n",
    "        weighting_batch = torch.FloatTensor(weighting_batch).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % 1000 == 0:\n",
    "            print(f\"  Step {step+1}/{steps_per_epoch} | Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    avg_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch+1:6.0f} | Avg Loss: {avg_loss:.6f} | Time: {end-start:.4f}s\")\n",
    "\n",
    "save_path = 'models/glove_model.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")\n",
    "\n",
    "import json\n",
    "metrics_path = 'models/metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "else:\n",
    "    metrics = {}\n",
    "\n",
    "metrics['GloVe'] = {\n",
    "    'window_size': 2,\n",
    "    'training_loss': avg_loss,\n",
    "    'training_time': time.time() - total_start\n",
    "}\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "print(\"Metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824edf1d",
   "metadata": {},
   "source": [
    "## 6. Evaluation & Comparison\n",
    "\n",
    "This section loads all trained models (plus Pre-trained GloVe) and generates:\n",
    "1. **Comparison Table**: Window Size, Loss, Time, Syntactic/Semantic Accuracy, correlation.\n",
    "2. **Detailed Analysis**: WordSim353 predictions vs Human Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe11705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters corpus (Full)...\n",
      "Corpus size: 54716 sentences\n",
      "Building vocabulary...\n",
      "Vocabulary size: 11678\n",
      "Loading models...\n",
      "Skipgram loaded.\n",
      "SkipgramNEG loaded.\n",
      "GloVe loaded.\n",
      "Loading Gensim GloVe (glove-twitter-25)...\n",
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
      "Gensim GloVe loaded.\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Model           Window   Loss       Time(s)    Sem Acc    Syn Acc    Spearman  \n",
      "--------------------------------------------------------------------------------\n",
      "Skipgram        2        6.1143     34385.60   0.0059     0.0000     0.2667    \n",
      "SkipgramNeg     2        1.9767     1227.33    0.0000     0.0000     0.1818    \n",
      "GloVe           2        38.9339    1147.96    0.0000     0.0000     0.2333    \n",
      "Gensim          N/A      N/A        N/A        0.1502     0.0000     0.3595    \n",
      "\n",
      "\n",
      "--- WordSim353 Detailed Results (MSE/Y_true Analysis) ---\n",
      "\n",
      "Model: Skipgram\n",
      "Word 1          Word 2          Human (Y)  Model (Pred) Sq.Err    \n",
      "-----------------------------------------------------------------\n",
      "book            paper           7.46       -0.0878      -         \n",
      "plane           car             5.77       -0.3293      -         \n",
      "train           car             6.31       0.3413       -         \n",
      "telephone       communication   7.50       0.5093       -         \n",
      "television      radio           6.77       0.5978       -         \n",
      "media           radio           7.42       0.1505       -         \n",
      "bread           butter          6.19       0.3133       -         \n",
      "company         stock           7.08       0.3892       -         \n",
      "stock           market          8.08       0.4308       -         \n",
      "stock           phone           1.62       0.1486       -         \n",
      "stock           cd              1.31       -0.2751      -         \n",
      "stock           jaguar          0.92       -0.3074      -         \n",
      "stock           egg             1.81       -0.4476      -         \n",
      "stock           live            3.73       0.1862       -         \n",
      "stock           life            0.92       0.6122       -         \n",
      "... (showing first 15 of 173)\n",
      "\n",
      "Model: SkipgramNeg\n",
      "Word 1          Word 2          Human (Y)  Model (Pred) Sq.Err    \n",
      "-----------------------------------------------------------------\n",
      "book            paper           7.46       0.1422       -         \n",
      "plane           car             5.77       0.6629       -         \n",
      "train           car             6.31       0.8551       -         \n",
      "telephone       communication   7.50       0.8303       -         \n",
      "television      radio           6.77       0.8993       -         \n",
      "media           radio           7.42       0.8569       -         \n",
      "bread           butter          6.19       0.7220       -         \n",
      "company         stock           7.08       -0.4315      -         \n",
      "stock           market          8.08       -0.2308      -         \n",
      "stock           phone           1.62       0.1020       -         \n",
      "stock           cd              1.31       -0.0942      -         \n",
      "stock           jaguar          0.92       -0.2105      -         \n",
      "stock           egg             1.81       0.2265       -         \n",
      "stock           live            3.73       0.2842       -         \n",
      "stock           life            0.92       0.4499       -         \n",
      "... (showing first 15 of 173)\n",
      "\n",
      "Model: GloVe\n",
      "Word 1          Word 2          Human (Y)  Model (Pred) Sq.Err    \n",
      "-----------------------------------------------------------------\n",
      "book            paper           7.46       0.3326       -         \n",
      "plane           car             5.77       0.1799       -         \n",
      "train           car             6.31       0.0486       -         \n",
      "telephone       communication   7.50       -0.1541      -         \n",
      "television      radio           6.77       0.5531       -         \n",
      "media           radio           7.42       0.0571       -         \n",
      "bread           butter          6.19       0.1839       -         \n",
      "company         stock           7.08       0.5279       -         \n",
      "stock           market          8.08       0.7998       -         \n",
      "stock           phone           1.62       -0.7108      -         \n",
      "stock           cd              1.31       -0.6061      -         \n",
      "stock           jaguar          0.92       0.2845       -         \n",
      "stock           egg             1.81       0.1030       -         \n",
      "stock           live            3.73       -0.1167      -         \n",
      "stock           life            0.92       -0.2126      -         \n",
      "... (showing first 15 of 173)\n",
      "\n",
      "Model: Gensim\n",
      "Word 1          Word 2          Human (Y)  Model (Pred) Sq.Err    \n",
      "-----------------------------------------------------------------\n",
      "love            sex             6.77       0.7232       -         \n",
      "tiger           cat             7.35       0.7448       -         \n",
      "tiger           tiger           10.00      1.0000       -         \n",
      "book            paper           7.46       0.8159       -         \n",
      "computer        keyboard        7.62       0.8226       -         \n",
      "computer        internet        7.58       0.8099       -         \n",
      "plane           car             5.77       0.8189       -         \n",
      "train           car             6.31       0.8756       -         \n",
      "telephone       communication   7.50       0.5914       -         \n",
      "television      radio           6.77       0.8082       -         \n",
      "media           radio           7.42       0.7314       -         \n",
      "drug            abuse           6.85       0.7855       -         \n",
      "bread           butter          6.19       0.9308       -         \n",
      "cucumber        potato          5.92       0.8734       -         \n",
      "doctor          nurse           7.00       0.6589       -         \n",
      "... (showing first 15 of 352)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import gensim.downloader as api\n",
    "import os\n",
    "\n",
    "loader = DataLoader() # min_freq=5\n",
    "word2index = loader.get_word2index()\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "vocab = loader.vocab\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        pass # Not needed for inference\n",
    "\n",
    "class SkipgramNeg(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid        = nn.LogSigmoid()\n",
    "    def forward(self, center, outside, negative):\n",
    "        pass \n",
    "\n",
    "class Glove(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Glove, self).__init__()\n",
    "        self.center_embedding  = nn.Embedding(voc_size, emb_size)\n",
    "        self.outside_embedding = nn.Embedding(voc_size, emb_size)\n",
    "        self.center_bias       = nn.Embedding(voc_size, 1) \n",
    "        self.outside_bias      = nn.Embedding(voc_size, 1)\n",
    "    def forward(self, center, outside, coocs, weighting):\n",
    "        pass\n",
    "\n",
    "device = torch.device('cpu')\n",
    "EMB_SIZE = 10\n",
    "VOC_SIZE = loader.voc_size\n",
    "\n",
    "print(\"Loading models...\")\n",
    "\n",
    "model_sg = Skipgram(VOC_SIZE, EMB_SIZE)\n",
    "try:\n",
    "    model_path = 'models/skipgram_model.pth'\n",
    "    model_sg.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    print(\"Skipgram loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipgram load failed: {e}\")\n",
    "\n",
    "model_neg = SkipgramNeg(VOC_SIZE, EMB_SIZE)\n",
    "try:\n",
    "    model_path = 'models/skipgram_neg_model.pth'\n",
    "    model_neg.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    print(\"SkipgramNEG loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"SkipgramNEG load failed: {e}\")\n",
    "\n",
    "model_glove = Glove(VOC_SIZE, EMB_SIZE)\n",
    "try:\n",
    "    model_path = 'models/glove_model.pth'\n",
    "    model_glove.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    print(\"GloVe loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"GloVe load failed: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Loading Gensim GloVe (glove-twitter-25)...\")\n",
    "    model_gensim = api.load(\"glove-twitter-25\")\n",
    "    print(\"Gensim GloVe loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Gensim GloVe failed: {e}\")\n",
    "    model_gensim = None\n",
    "\n",
    "def get_vector(model, word, model_type='scratch'):\n",
    "    if model_type == 'gensim':\n",
    "        if word in model:\n",
    "            return model[word]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    if word not in word2index:\n",
    "        return None\n",
    "    idx = torch.LongTensor([word2index[word]])\n",
    "    \n",
    "    if isinstance(model, Skipgram) or isinstance(model, SkipgramNeg):\n",
    "        v = model.embedding_center(idx)\n",
    "        vec = v # Usually we just use v_c. But averaging is also common. Notebook 1 used (c+o)/2.\n",
    "        u = model.embedding_outside(idx)\n",
    "        vec = (v + u) / 2\n",
    "        return vec.detach().numpy()[0]\n",
    "    \n",
    "    if isinstance(model, Glove):\n",
    "        v = model.center_embedding(idx)\n",
    "        u = model.outside_embedding(idx)\n",
    "        vec = (v + u) / 2\n",
    "        return vec.detach().numpy()[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def evaluate_correlation(model, model_type='scratch'):\n",
    "    pairs = []\n",
    "    try:\n",
    "        data_path = 'wordsim353/combined.csv'\n",
    "        with open(data_path, 'r') as f:\n",
    "            next(f) # skip header\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) >= 3:\n",
    "                    pairs.append((parts[0].lower(), parts[1].lower(), float(parts[2])))\n",
    "    except FileNotFoundError:\n",
    "        print(\"wordsim353/combined.csv not found.\")\n",
    "        return 0.0\n",
    "\n",
    "    preds = []\n",
    "    humans = []\n",
    "    \n",
    "    for w1, w2, score in pairs:\n",
    "        v1 = get_vector(model, w1, model_type)\n",
    "        v2 = get_vector(model, w2, model_type)\n",
    "        \n",
    "        if v1 is not None and v2 is not None:\n",
    "            sim = cosine_similarity(v1, v2)\n",
    "            preds.append(sim)\n",
    "            humans.append(score)\n",
    "            \n",
    "    if not preds:\n",
    "        return 0.0\n",
    "        \n",
    "    corr, _ = scipy.stats.spearmanr(preds, humans)\n",
    "    return corr\n",
    "\n",
    "def evaluate_analogies(model, model_type='scratch'):\n",
    "    \n",
    "    sem_correct = 0\n",
    "    sem_total = 0\n",
    "    syn_correct = 0\n",
    "    syn_total = 0\n",
    "    \n",
    "    current_section = None\n",
    "    \n",
    "    try:\n",
    "        data_path = 'word-test.v1.txt'\n",
    "        with open(data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(':'):\n",
    "                    current_section = line.strip()\n",
    "                    continue\n",
    "                \n",
    "                if current_section == ': capital-common-countries':\n",
    "                    is_semantic = True\n",
    "                elif current_section == ': past-tense':\n",
    "                    is_semantic = False\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.lower().split()\n",
    "                if len(parts) != 4: continue\n",
    "                \n",
    "                w_a, w_b, w_c, w_d = parts\n",
    "                \n",
    "                v_a = get_vector(model, w_a, model_type)\n",
    "                v_b = get_vector(model, w_b, model_type)\n",
    "                v_c = get_vector(model, w_c, model_type)\n",
    "                \n",
    "                if v_a is None or v_b is None or v_c is None:\n",
    "                    continue\n",
    "                \n",
    "                target = v_b - v_a + v_c\n",
    "                \n",
    "                if model_type == 'gensim':\n",
    "                    try:\n",
    "                        res = model.most_similar(positive=[w_b, w_c], negative=[w_a], topn=1)\n",
    "                        pred_word = res[0][0]\n",
    "                    except:\n",
    "                        pred_word = \"\"\n",
    "                else:\n",
    "                    \n",
    "                    if not hasattr(model, 'embeddings_matrix'):\n",
    "                        if isinstance(model, Skipgram) or isinstance(model, SkipgramNeg):\n",
    "                            model.embeddings_matrix = (model.embedding_center.weight + model.embedding_outside.weight).detach().numpy() / 2\n",
    "                        elif isinstance(model, Glove):\n",
    "                            model.embeddings_matrix = (model.center_embedding.weight + model.outside_embedding.weight).detach().numpy() / 2\n",
    "                            \n",
    "                    target = target / np.linalg.norm(target)\n",
    "                    \n",
    "                    sims = np.dot(model.embeddings_matrix, target)\n",
    "                    \n",
    "                    if not hasattr(model, 'norm_embeddings_matrix'):\n",
    "                        norm = np.linalg.norm(model.embeddings_matrix, axis=1, keepdims=True)\n",
    "                        model.norm_embeddings_matrix = model.embeddings_matrix / (norm + 1e-9)\n",
    "                        \n",
    "                    sims = np.dot(model.norm_embeddings_matrix, target)\n",
    "                    best_idx = np.argmax(sims)\n",
    "                    pred_word = index2word[best_idx]\n",
    "                \n",
    "                if pred_word == w_d:\n",
    "                    if is_semantic: sem_correct += 1\n",
    "                    else: syn_correct += 1\n",
    "                \n",
    "                if is_semantic: sem_total += 1\n",
    "                else: syn_total += 1\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(\"word-test.v1.txt not found.\")\n",
    "        \n",
    "    sem_acc = sem_correct / sem_total if sem_total > 0 else 0.0\n",
    "    syn_acc = syn_correct / syn_total if syn_total > 0 else 0.0\n",
    "    \n",
    "    return sem_acc, syn_acc\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "\n",
    "import json\n",
    "metrics_path = 'models/metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        training_metrics = json.load(f)\n",
    "else:\n",
    "    training_metrics = {}\n",
    "\n",
    "models = {\n",
    "    'Skipgram': (model_sg, 'scratch'),\n",
    "    'SkipgramNeg': (model_neg, 'scratch'),\n",
    "    'GloVe': (model_glove, 'scratch'),\n",
    "    'Gensim': (model_gensim, 'gensim')\n",
    "}\n",
    "\n",
    "print(f\"{'Model':<15} {'Window':<8} {'Loss':<10} {'Time(s)':<10} {'Sem Acc':<10} {'Syn Acc':<10} {'Spearman':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, (m, m_type) in models.items():\n",
    "    if m is None:\n",
    "        print(f\"{name:<15} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n",
    "        continue\n",
    "        \n",
    "    t_metrics = training_metrics.get(name, {})\n",
    "    window = t_metrics.get('window_size', 'N/A')\n",
    "    loss = t_metrics.get('training_loss', 'N/A')\n",
    "    time_taken = t_metrics.get('training_time', 'N/A')\n",
    "    \n",
    "    if m_type == 'gensim':\n",
    "        window = 'N/A' # Pre-trained\n",
    "        loss = 'N/A'\n",
    "        time_taken = 'N/A'\n",
    "\n",
    "    if isinstance(loss, float): loss = f\"{loss:.4f}\"\n",
    "    if isinstance(time_taken, float): time_taken = f\"{time_taken:.2f}\"\n",
    "    if isinstance(window, int): window = str(window)\n",
    "\n",
    "    corr = evaluate_correlation(m, m_type)\n",
    "    sem, syn = evaluate_analogies(m, m_type)\n",
    "    \n",
    "    print(f\"{name:<15} {window:<8} {loss:<10} {time_taken:<10} {sem:<10.4f} {syn:<10.4f} {corr:<10.4f}\")\n",
    "\n",
    "print(\"\\n\\n--- WordSim353 Detailed Results (MSE/Y_true Analysis) ---\")\n",
    "def get_correlation_details(model, model_type='scratch'):\n",
    "    pairs = []\n",
    "    try:\n",
    "        data_path = 'wordsim353/combined.csv'\n",
    "        with open(data_path, 'r') as f:\n",
    "            next(f) # skip header\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) >= 3:\n",
    "                    pairs.append((parts[0].lower(), parts[1].lower(), float(parts[2])))\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "    details = []\n",
    "    for w1, w2, score in pairs:\n",
    "        v1 = get_vector(model, w1, model_type)\n",
    "        v2 = get_vector(model, w2, model_type)\n",
    "        \n",
    "        if v1 is not None and v2 is not None:\n",
    "            sim = cosine_similarity(v1, v2)\n",
    "            details.append((w1, w2, score, sim))\n",
    "    return details\n",
    "\n",
    "for name, (m, m_type) in models.items():\n",
    "    if m is None: continue\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    details = get_correlation_details(m, m_type)\n",
    "    if not details:\n",
    "        print(\"No data found.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"{'Word 1':<15} {'Word 2':<15} {'Human (Y)':<10} {'Model (Pred)':<12} {'Sq.Err':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    mse_sum = 0\n",
    "    count = 0\n",
    "    for w1, w2, human, pred in details[:15]:\n",
    "        \n",
    "        print(f\"{w1:<15} {w2:<15} {human:<10.2f} {pred:<12.4f} {'-':<10}\")\n",
    "    print(f\"... (showing first 15 of {len(details)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8f313",
   "metadata": {},
   "source": [
    "## 7. Web Application\n",
    "\n",
    "The web application allows to search for relevant context using the trained embeddings.\n",
    "\n",
    "### How to Run:\n",
    "\n",
    "1. Open terminal.\n",
    "2. Make sure it is under the repositary root folder\n",
    "3. Run the following command:\n",
    "   ```bash\n",
    "   python app/app.py\n",
    "   ```\n",
    "4. Open the browser and go to `http://127.0.0.1:5000`.\n",
    "\n",
    "### Features:\n",
    "- Type a query phrase.\n",
    "- The app converts the query to an embedding vector.\n",
    "- It finds the top 10 most semantically similar sentences from the Reuters corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4233de9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
